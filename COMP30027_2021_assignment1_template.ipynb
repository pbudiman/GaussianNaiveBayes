{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 1: Pose classification with naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):**    1013239  &  1012861\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import pow\n",
    "from math import pi\n",
    "from math import log \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# open & store data from training file\n",
    "def open_train_file(train_attr_vals, train_classes,filename):\n",
    "    f = open(filename,'r')\n",
    "    \n",
    "    for line in f.readlines()[0:]:\n",
    "        cleaned_line = line.strip().split(\",\")\n",
    "        attributes = cleaned_line[1:]\n",
    "        class_name = cleaned_line[0]\n",
    "        \n",
    "        str_to_float(attributes)\n",
    "        \n",
    "        if (mean(attributes) == 9999):\n",
    "            continue\n",
    "        else:\n",
    "            train_attr_vals.append(attributes)\n",
    "            train_classes.append(class_name)\n",
    "        \n",
    "    f.close\n",
    "    return \n",
    "\n",
    "#impute missing values from 9999 to 0 \n",
    "def remove_missing_values(train_attr_vals):\n",
    "    for instance in train_attr_vals:\n",
    "        for i in range(len(instance)):\n",
    "            if(instance[i]==9999):\n",
    "                instance[i]=0          \n",
    "    return\n",
    "\n",
    "#convert elements in array from string to float                \n",
    "def str_to_float(attributes):\n",
    "    for i in range(len(attributes)):\n",
    "        attributes[i]=float(attributes[i])\n",
    "    return \n",
    "\n",
    "#put training instances into dictionary based on class\n",
    "def put_into_dict(train_attr_vals,train_classes,class_dict,class_count_dict):\n",
    "    instance_num = len(train_attr_vals)\n",
    "    \n",
    "    for i in range(instance_num):\n",
    "        attributes = train_attr_vals[i]\n",
    "        class_name = train_classes[i]\n",
    "        if class_dict.get(class_name) is None:\n",
    "            class_dict[class_name]=[]\n",
    "        # appending each\n",
    "        class_dict[class_name].append(attributes)\n",
    "        class_count_dict[class_name] += 1\n",
    "    return class_dict, class_count_dict\n",
    "\n",
    "# preprocess the training set : impute missing values and store into wanted structure\n",
    "def preprocess(train_attr_vals, train_classes, class_dict, class_count_dict):\n",
    "    \n",
    "    train_filename = \"COMP30027_2021_assignment1_data/train.csv\"\n",
    "    # open training file and store into arrays\n",
    "    open_train_file(train_attr_vals, train_classes,train_filename)\n",
    "    \n",
    "    # impute missing values\n",
    "    remove_missing_values(train_attr_vals)\n",
    "    \n",
    "    # put instances into dictionary based on classes\n",
    "    put_into_dict(train_attr_vals,train_classes,class_dict,class_count_dict)\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "# This function should calculate prior probabilities and likelihoods from the training data and using\n",
    "# them to build a naive Bayes model\n",
    "\n",
    "#calculate mean from array\n",
    "def mean(array):\n",
    "    return (sum(array)/len(array))\n",
    "\n",
    "#calculate standard deviation from array and calculated mean\n",
    "def standard_deviation(array,mean_val):\n",
    "    total = 0\n",
    "    for one in array:\n",
    "        total+=(pow((one-mean_val),2))\n",
    "    result = sqrt(total/(len(array)-1))\n",
    "    return result\n",
    "\n",
    "#train using the training data\n",
    "def train(class_dict, class_count_dict,training_details,attr_length,total_inst):\n",
    "    \n",
    "    # training_details dictionary format {key : [[means], [standard deviation], class_prob]}\n",
    "    for key in class_dict.keys():\n",
    "        \n",
    "        if training_details.get(key) is None:\n",
    "            training_details[key]=[]\n",
    "            \n",
    "        #array to store each attributes' mean value\n",
    "        mean_array=[]\n",
    "        \n",
    "        #array to store each standard deviations' value\n",
    "        std_dev_array=[]\n",
    "        \n",
    "        for i in range(attr_length):\n",
    "            attr_array = [instance[i] for instance in class_dict[key]]\n",
    "            \n",
    "            #find mean and standard deviation of current attribute value\n",
    "            mean_val = mean(attr_array)\n",
    "            std_dev_val = standard_deviation(attr_array,mean_val) \n",
    "            \n",
    "            mean_array.append(mean_val)\n",
    "            std_dev_array.append(std_dev_val)\n",
    "            \n",
    "        #append mean, standard deviation & class probability to training details dictionary\n",
    "        training_details[key].append(mean_array)\n",
    "        training_details[key].append(std_dev_array)\n",
    "        class_prob = class_count_dict[key]/total_inst\n",
    "        training_details[key].append(class_prob)\n",
    "        \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT\n",
    "# This function should predict classes for new items in a test dataset (for the purposes of this assignment, you\n",
    "# can re-use the training data as a test set)\n",
    "\n",
    "#calculate gaussian distribution\n",
    "def gaussian_distribution(val,mean,std_dev):\n",
    "    exponential = exp(-(1/2)* (pow(((val-mean)/std_dev),2)))\n",
    "    result = (1/(std_dev * sqrt(2*pi)))* exponential\n",
    "    return result\n",
    "\n",
    "#to handle log of 0 \n",
    "def take_log(val):\n",
    "    if(val==0):\n",
    "        return 0\n",
    "    else:\n",
    "        return log(val)\n",
    "\n",
    "#calculate the probability of the test instance being classified as each classes\n",
    "def probability(instance,training_details,attr_num,class_num):\n",
    "    probs = defaultdict()\n",
    "    \n",
    "    #find the likelihood/probability of the instance in each class\n",
    "    for key in training_details.keys():\n",
    "        total_prob=0\n",
    "        sum_gaussian_prob=0\n",
    "        \n",
    "        # likelihood of the instance's attribute based on the class\n",
    "        for i in range(attr_num):\n",
    "            attr_mean = training_details[key][0][i]\n",
    "            attr_std_dev = training_details[key][1][i]\n",
    "            \n",
    "            gauss_prob = gaussian_distribution(instance[i],attr_mean,attr_std_dev)\n",
    "            #take_log here to handle log(0) for now as log(0) cant be computed\n",
    "            sum_gaussian_prob+=take_log(gauss_prob)\n",
    "            \n",
    "        # probability of the instance being a class :  log(class prob) + sum(log(each attribute))\n",
    "        total_prob+=sum_gaussian_prob\n",
    "        class_prob=training_details[key][2]\n",
    "        # adding log of class prob\n",
    "        total_prob+=log(class_prob)\n",
    "        \n",
    "        # put in dictionary\n",
    "        probs[key] = total_prob\n",
    "\n",
    "    return probs\n",
    "\n",
    "# predict the classes of test intances\n",
    "def predict(training_details,attr_num,class_num,test_attr_vals,test_actual_class):\n",
    "    \n",
    "    test_filename=\"COMP30027_2021_assignment1_data/test.csv\"\n",
    "    # open testing file & store data\n",
    "    open_train_file(test_attr_vals,test_actual_class,test_filename)\n",
    "    remove_missing_values(test_attr_vals)\n",
    "    \n",
    "    predicted_classes=[]\n",
    "    for instance in test_attr_vals:\n",
    "        # dictionary to store the probability \n",
    "        # of each instances being classified as each classes\n",
    "        probability_dict = probability(instance,training_details,attr_num,class_num)\n",
    "        #find the class with the highest probability\n",
    "        max_prob_class = max(probability_dict, key=probability_dict.get)\n",
    "        predicted_classes.append(max_prob_class)\n",
    "    \n",
    "    return predicted_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE\n",
    "# This function should evaluate the prediction performance by comparing your model’s class outputs to ground\n",
    "# truth labels\n",
    "\n",
    "def evaluate(test_actual_class,predicted_classes):    \n",
    "        \n",
    "    correct_label = 0\n",
    "    test_num=len(test_actual_class)\n",
    "    for i in range(test_num):\n",
    "        if(test_actual_class[i]==predicted_classes[i]):\n",
    "            correct_label+=1\n",
    "\n",
    "    accuracy = (correct_label / test_num) * 100\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  73.21428571428571 %\n"
     ]
    }
   ],
   "source": [
    "#RUN HERE \n",
    "\n",
    "#store value of attributes of each instance\n",
    "train_attr_vals = []\n",
    "\n",
    "#store class of training isntances\n",
    "train_classes = []\n",
    "\n",
    "#class_dict : store all instances per class \n",
    "class_dict = defaultdict()\n",
    "\n",
    "#class_count_dict: store number of instances per class\n",
    "class_count_dict = defaultdict(int)\n",
    "\n",
    "#store the details of each class after training\n",
    "training_details = defaultdict()\n",
    "\n",
    "#number of attributes\n",
    "attr_num = 0\n",
    "\n",
    "#number of instances\n",
    "total_instances = 0\n",
    "\n",
    "#class_dict : store all instances per class & class_count_dict: store number of instances per class\n",
    "preprocess(train_attr_vals, train_classes, class_dict, class_count_dict)\n",
    "\n",
    "attr_num = len(train_attr_vals[0])\n",
    "total_instances = sum([class_count_dict[key] for key in class_count_dict.keys()])\n",
    "\n",
    "#train the data\n",
    "#result is training_details dict format - {class_name : [[means], [standard deviation], class_prob]}\n",
    "train(class_dict, class_count_dict, training_details, attr_num, total_instances)\n",
    "\n",
    "#store values of testing instances\n",
    "test_attr_vals=[]\n",
    "\n",
    "#store actual class of testing instances\n",
    "test_actual_class=[]\n",
    "\n",
    "#predicted classes of the testing instances\n",
    "predicted_class_gaussian = predict(training_details,attr_num,len(training_details.keys()),test_attr_vals,test_actual_class)\n",
    "\n",
    "accuracy = evaluate(test_actual_class,predicted_class_gaussian)\n",
    "print(\"Accuracy is \", accuracy,\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to **two** questions of your choosing.\n",
    "\n",
    "If you are in a group of 2, you will respond to **four** questions of your choosing.\n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer should be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Since this is a multiclass classification problem, there are multiple ways to compute precision, recall, and F-score for this classifier. Implement at least two of the methods from the \"Model Evaluation\" lecture and discuss any differences between them. (The implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions Q1 : macro averaging vs micro averaging\n",
    "\n",
    "#create confusion matrix\n",
    "def confusion_matrix(predicted_classes, test_actual_class, class_dict):\n",
    "    \n",
    "    # confusion matrix dataframe\n",
    "    matrix = pd.DataFrame()\n",
    "    classes = np.unique(np.array(predicted_classes))\n",
    "    classes = np.append(classes,['fn'])\n",
    "    matrix['actual'] = classes\n",
    "    \n",
    "    #initialise all columns and rows\n",
    "    zeros = pd.Series(np.zeros((len(classes),), dtype=int))\n",
    "    for i in range(len(classes)):\n",
    "        matrix[classes[i]] = zeros\n",
    "        \n",
    "    matrix = matrix.set_index('actual')\n",
    "    matrix.index.name = \"predicted ↓ actual →\"\n",
    "    \n",
    "    for j in range(len(predicted_classes)):\n",
    "        matrix.loc[predicted_classes[j],test_actual_class[j]]+=1\n",
    "    \n",
    "    #calculate fn,tp,fp\n",
    "    FP=[]\n",
    "    FN=[]\n",
    "    TP=[]\n",
    "    for key in classes:\n",
    "        # get the tp,fn,fp from the confusion matrix\n",
    "        tp_one = matrix.loc[key,key] \n",
    "        fp_one = sum(matrix.loc[key,:]) - tp_one\n",
    "        fn_one = sum(matrix.loc[:,key]) - tp_one\n",
    "        FP.append(fp_one)\n",
    "        FN.append(fn_one)\n",
    "        TP.append(tp_one)  \n",
    "    \n",
    "    #put fn,tp,fp into dataframe\n",
    "    matrix['fp'] = FP\n",
    "    matrix['tp'] = TP\n",
    "    for i in range(len(FN)):\n",
    "        matrix.loc['fn',classes[i]]= FN[i]\n",
    "    del matrix['fn']\n",
    "    return matrix\n",
    "\n",
    "#run the macro averaging method   \n",
    "def macro_averaging(predicted_classes, test_actual_class, class_dict):\n",
    "    matrix = confusion_matrix(predicted_classes, test_actual_class, class_dict)\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    for i in class_dict.keys():\n",
    "        # get the tp,fn,fp from the confusion matrix\n",
    "        tp = matrix['tp'][i]\n",
    "        fn = matrix[i].loc['fn']\n",
    "        fp = matrix['fp'][i]\n",
    "        precision += (tp/(tp+fp)) #calculate sum of total precision of each class\n",
    "        recall += (tp/(tp+fn)) #calculate sum of total recall of each class\n",
    "    \n",
    "    macro_precision = precision/len(class_dict)\n",
    "    macro_recall = recall/len(class_dict)\n",
    "    fscore_macro = (2*macro_precision*macro_recall)/(macro_precision+macro_recall)\n",
    "    return macro_precision, macro_recall, fscore_macro\n",
    "\n",
    "#run the micro averaging method\n",
    "def micro_averaging(predicted_classes, test_actual_class, class_dict):\n",
    "    matrix = confusion_matrix(predicted_classes, test_actual_class, class_dict)\n",
    "    total_tp = 0 #total true positive\n",
    "    total_tp_fp = 0 #total true positive plus false positive (denominator for micro precision)\n",
    "    total_tp_fn = 0 #total true positive plus false negative (denominator for micro recall)\n",
    "    for i in class_dict.keys():\n",
    "        # get the tp,fn,fp from the confusion matrix\n",
    "        tp = matrix['tp'][i]\n",
    "        fn = matrix[i].loc['fn']\n",
    "        fp = matrix['fp'][i]\n",
    "        total_tp += tp\n",
    "        total_tp_fp += (tp+fp)\n",
    "        total_tp_fn += (tp+fn)\n",
    "\n",
    "    micro_precision = total_tp/total_tp_fp\n",
    "    micro_recall = total_tp/total_tp_fn\n",
    "    fscore_micro = (2*micro_precision*micro_recall)/(micro_precision+micro_recall)\n",
    "    return micro_precision, micro_recall, fscore_micro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bridge</th>\n",
       "      <th>childs</th>\n",
       "      <th>downwarddog</th>\n",
       "      <th>mountain</th>\n",
       "      <th>plank</th>\n",
       "      <th>seatedforwardbend</th>\n",
       "      <th>tree</th>\n",
       "      <th>trianglepose</th>\n",
       "      <th>warrior1</th>\n",
       "      <th>warrior2</th>\n",
       "      <th>fp</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted ↓ actual →</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bridge</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>childs</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downwarddog</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mountain</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plank</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seatedforwardbend</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trianglepose</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warrior1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warrior2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bridge  childs  downwarddog  mountain  plank  \\\n",
       "predicted ↓ actual →                                                 \n",
       "bridge                     6       0            0         0      1   \n",
       "childs                     3      11            3         0      0   \n",
       "downwarddog                3       0           12         0      0   \n",
       "mountain                   0       0            0        26      0   \n",
       "plank                      0       0            0         0      5   \n",
       "seatedforwardbend          2       1            0         0      1   \n",
       "tree                       0       0            0         4      0   \n",
       "trianglepose               0       0            0         0      2   \n",
       "warrior1                   0       0            0         0      0   \n",
       "warrior2                   0       0            0         0      0   \n",
       "fn                         8       1            3         4      4   \n",
       "\n",
       "                      seatedforwardbend  tree  trianglepose  warrior1  \\\n",
       "predicted ↓ actual →                                                    \n",
       "bridge                                0     0             0         0   \n",
       "childs                                5     0             0         0   \n",
       "downwarddog                           1     1             0         0   \n",
       "mountain                              0     0             0         0   \n",
       "plank                                 0     0             0         0   \n",
       "seatedforwardbend                     3     0             0         0   \n",
       "tree                                  0     3             0         0   \n",
       "trianglepose                          0     0             4         0   \n",
       "warrior1                              0     2             0         5   \n",
       "warrior2                              0     0             0         0   \n",
       "fn                                    6     3             0         0   \n",
       "\n",
       "                      warrior2  fp  tp  \n",
       "predicted ↓ actual →                    \n",
       "bridge                       0   1   6  \n",
       "childs                       0  11  11  \n",
       "downwarddog                  0   5  12  \n",
       "mountain                     0   0  26  \n",
       "plank                        0   0   5  \n",
       "seatedforwardbend            0   4   3  \n",
       "tree                         0   4   3  \n",
       "trianglepose                 0   2   4  \n",
       "warrior1                     1   3   5  \n",
       "warrior2                     7   0   7  \n",
       "fn                           1   0   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Precision       Recall         F-score    \n",
      "Macro-averaging     72.12          72.76          72.44     \n",
      "Micro-averaging     73.21          73.21          73.21     \n"
     ]
    }
   ],
   "source": [
    "# RUN HERE FOR Q1 AFTER RUNNING FUNCTIONS ABOVE\n",
    "macro_precision, macro_recall, fscore_macro = macro_averaging(predicted_class_gaussian, test_actual_class, class_dict)\n",
    "micro_precision, micro_recall, fscore_micro = micro_averaging(predicted_class_gaussian, test_actual_class, class_dict)\n",
    "display(confusion_matrix(predicted_class_gaussian, test_actual_class, class_dict))\n",
    "\n",
    "\n",
    "print(\"{:<15}{:^15}{:^15}{:^15}\".format(\"\", \"Precision\", \"Recall\", \"F-score\"))\n",
    "print(\"{:<15}{:^15}{:^15}{:^15}\".format(\"Macro-averaging\", round(macro_precision*100, 2) , round(macro_recall*100,2), round(fscore_macro*100,2)))\n",
    "print(\"{:<15}{:^15}{:^15}{:^15}\".format(\"Micro-averaging\", round(micro_precision*100, 2) , round(micro_recall*100,2), round(fscore_micro*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "The Gaussian naıve Bayes classifier assumes that numeric attributes come from a Gaussian distribution. Is this assumption always true for the numeric attributes in this dataset? Identify some cases where the Gaussian assumption is violated and describe any evidence (or lack thereof) that this has some effect on the classifier’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Implement a kernel density estimate (KDE) naive Bayes classifier and compare its performance to the Gaussian naive Bayes classifier. Recall that KDE has kernel bandwidth as a free parameter -- you can choose an arbitrary value for this, but a value in the range 5-25 is recommended. Discuss any differences you observe between the Gaussian and KDE naive Bayes classifiers. (As with the Gaussian naive Bayes, this KDE naive Bayes implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional functions for Q3\n",
    "\n",
    "# train using kde\n",
    "def KDE(kernel_bandwidth, test_instance, class_dict):\n",
    "    attribute_num = len(test_instance)\n",
    "    \n",
    "    total_instance_n = sum([len(class_dict[key]) for key in class_dict.keys()])\n",
    "    \n",
    "    # dictionary to store probabilities of the test instance classified as each class\n",
    "    # {class name: probability}\n",
    "    probs = defaultdict()\n",
    "    \n",
    "    for key in class_dict.keys():\n",
    "        train_instances = class_dict[key]\n",
    "        train_instance_num = len(class_dict[key])\n",
    "        test_instance_prob = 0\n",
    "        \n",
    "        # for each attribute value of the test instance \n",
    "        for i in range(attribute_num):\n",
    "            \n",
    "            # array containing all values of the attributes from training data per class\n",
    "            column_i = [one_train[i] for one_train in train_instances]\n",
    "            \n",
    "            # total of probability of each attribute's val\n",
    "            col_i_prob = 0\n",
    "       \n",
    "            for j in range(len(column_i)):\n",
    "                # gaussian_distribution(val,mean,std_dev)\n",
    "                # 𝜙(𝑥−𝑥i)\n",
    "                gaussian_kde = (gaussian_distribution(test_instance[i],column_i[j],kernel_bandwidth))\n",
    "                # sum(𝜙(𝑥−𝑥i))\n",
    "                col_i_prob += (gaussian_kde)\n",
    "            # sum(𝜙(𝑥−𝑥i)) / num of train instance\n",
    "            col_i_prob /= train_instance_num\n",
    "            \n",
    "            test_instance_prob+=take_log(col_i_prob)\n",
    "            \n",
    "        # log(class probability) + log(sum(𝜙(𝑥−𝑥i)) / num of train instance)\n",
    "        test_instance_prob+=take_log(len(class_dict[key])/total_instance_n)\n",
    "        \n",
    "        #store the probability being classified to current class into dictionary\n",
    "        probs[key] = test_instance_prob\n",
    "\n",
    "    return probs\n",
    "\n",
    "# predict using kde\n",
    "def predict_kde(bandwidth,test_attr_vals_q3,class_dict):\n",
    "    \n",
    "    predicted_classes=[]\n",
    "    for instance in test_attr_vals_q3:\n",
    "        # dictionary to store the probability \n",
    "        # of the instance being classified as each classes\n",
    "        probability_dict = KDE(bandwidth,instance,class_dict)\n",
    "                 \n",
    "        #find the class with the highest probability\n",
    "        max_prob_class = max(probability_dict, key=probability_dict.get)\n",
    "\n",
    "        predicted_classes.append(max_prob_class)\n",
    "    \n",
    "    return predicted_classes\n",
    "\n",
    "# similarity when using kde vs gaussian naive bayes\n",
    "def kde_vs_gaussian(predicted_kde, predicted_gaussian):\n",
    "    same = 0\n",
    "    for i in range(len(predicted_kde)):\n",
    "        if (predicted_kde[i] == predicted_gaussian[i]):\n",
    "            same += 1\n",
    "    return (same/len(predicted_kde))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bridge</th>\n",
       "      <th>childs</th>\n",
       "      <th>downwarddog</th>\n",
       "      <th>mountain</th>\n",
       "      <th>plank</th>\n",
       "      <th>seatedforwardbend</th>\n",
       "      <th>tree</th>\n",
       "      <th>trianglepose</th>\n",
       "      <th>warrior1</th>\n",
       "      <th>warrior2</th>\n",
       "      <th>fp</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted ↓ actual →</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bridge</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>childs</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downwarddog</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mountain</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plank</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seatedforwardbend</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trianglepose</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warrior1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warrior2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bridge  childs  downwarddog  mountain  plank  \\\n",
       "predicted ↓ actual →                                                 \n",
       "bridge                     8       0            1         0      2   \n",
       "childs                     2       9            1         0      0   \n",
       "downwarddog                3       0           11         0      0   \n",
       "mountain                   0       0            0        26      0   \n",
       "plank                      1       0            1         0      7   \n",
       "seatedforwardbend          0       3            1         0      0   \n",
       "tree                       0       0            0         4      0   \n",
       "trianglepose               0       0            0         0      0   \n",
       "warrior1                   0       0            0         0      0   \n",
       "warrior2                   0       0            0         0      0   \n",
       "fn                         6       3            4         4      2   \n",
       "\n",
       "                      seatedforwardbend  tree  trianglepose  warrior1  \\\n",
       "predicted ↓ actual →                                                    \n",
       "bridge                                0     1             0         0   \n",
       "childs                                4     0             0         0   \n",
       "downwarddog                           0     0             0         0   \n",
       "mountain                              0     0             0         0   \n",
       "plank                                 1     0             0         0   \n",
       "seatedforwardbend                     4     0             0         0   \n",
       "tree                                  0     4             0         1   \n",
       "trianglepose                          0     0             4         0   \n",
       "warrior1                              0     1             0         4   \n",
       "warrior2                              0     0             0         0   \n",
       "fn                                    5     2             0         1   \n",
       "\n",
       "                      warrior2  fp  tp  \n",
       "predicted ↓ actual →                    \n",
       "bridge                       0   4   8  \n",
       "childs                       0   7   9  \n",
       "downwarddog                  0   3  11  \n",
       "mountain                     0   0  26  \n",
       "plank                        0   3   7  \n",
       "seatedforwardbend            0   4   4  \n",
       "tree                         1   6   4  \n",
       "trianglepose                 0   0   4  \n",
       "warrior1                     0   1   4  \n",
       "warrior2                     7   0   7  \n",
       "fn                           1   0   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between KDE and Gaussian is:  76.79 %\n",
      "KDE Accuracy is : 75.0\n"
     ]
    }
   ],
   "source": [
    "# RUN HERE FOR Q3 AFTER RUNNING FUNCTIONS ABOVE\n",
    "\n",
    "test_attr_vals_q3=[]\n",
    "test_actual_class_q3=[]\n",
    "\n",
    "# open testing file & store data\n",
    "test_filename = \"COMP30027_2021_assignment1_data/test.csv\"\n",
    "open_train_file(test_attr_vals_q3,test_actual_class_q3,test_filename)\n",
    "# impute missing values\n",
    "\n",
    "remove_missing_values(test_attr_vals_q3)\n",
    "\n",
    "# find predicted classes of each test instance\n",
    "predicted_class_kde = predict_kde(10,test_attr_vals_q3,class_dict)\n",
    "\n",
    "# find accuracy when using kde naive bayes\n",
    "accuracy_kde_q3 = evaluate(test_actual_class_q3, predicted_class_kde)\n",
    "\n",
    "#find similarity between kde and gaussian naive bayes in predicting classes\n",
    "difference_kde_gaussian = kde_vs_gaussian(predicted_class_kde, predicted_class_gaussian)\n",
    "\n",
    "display(confusion_matrix(predicted_class_kde, test_actual_class_q3, class_dict))\n",
    "\n",
    "print(\"Similarity between KDE and Gaussian is: \", round(difference_kde_gaussian,2), \"%\")\n",
    "\n",
    "print(\"KDE Accuracy is :\",accuracy_kde_q3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "Instead of using an arbitrary kernel bandwidth for the KDE naive Bayes classifier, use random hold-out or cross-validation to choose the kernel bandwidth. Discuss how this changes the model performance compared to using an arbitrary kernel bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional functions for 4\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "\n",
    "#preprocess training dataset for q4\n",
    "def preprocess_q4(train_attr_vals_q4, train_classes_q4):\n",
    "    \n",
    "    train_filename = \"COMP30027_2021_assignment1_data/train.csv\"\n",
    "    # open training file and store into arrays\n",
    "    open_train_file(train_attr_vals_q4, train_classes_q4,train_filename)\n",
    "    \n",
    "    # impute missing values\n",
    "    remove_missing_values(train_attr_vals_q4)\n",
    "    return \n",
    "\n",
    "#cross validation to choose bandwidth\n",
    "def cross_val_bandwidth(class_dict_q4,class_count_dict_q4,train_attr_vals_q4,train_classes_q4):\n",
    "\n",
    "    bandwidth_min=5\n",
    "    bandwidth_max=26\n",
    "\n",
    "    kf = KFold(n_splits=7, random_state=1,shuffle=True)\n",
    "    \n",
    "    # store the bandwidth which results in the highest probability for each partition\n",
    "    kf_bandwidth_max=[]\n",
    "\n",
    "    for train_index , test_index in kf.split(train_attr_vals_q4):\n",
    "        print(\"cross validation bandwidth running...\")\n",
    "        k_train_ins = [train_attr_vals_q4[i] for i in train_index]\n",
    "        k_train_class = [train_classes_q4[i] for i in train_index] \n",
    "        k_test_ins = [train_attr_vals_q4[i] for i in test_index]\n",
    "        k_test_class = [train_classes_q4[i] for i in test_index]\n",
    "\n",
    "        put_into_dict(k_train_ins,k_train_class,class_dict_q4,class_count_dict_q4)\n",
    "\n",
    "        # dictionary to store accuracy of current partition with different bandwidth\n",
    "        # {bandwidth : accuracy}\n",
    "        diff_bandwidth_accuracy = defaultdict()\n",
    "        \n",
    "        # try few different bandwidths for each partition\n",
    "        for i in range(bandwidth_min,bandwidth_max,5):\n",
    "            predicted = predict_kde(i,k_test_ins,class_dict_q4)\n",
    "            accuracy_kde = evaluate(k_test_class, predicted)\n",
    "            diff_bandwidth_accuracy[i] = accuracy_kde\n",
    "            \n",
    "        # find bandwidth with the highest probability\n",
    "        max_prob_bandwidth = max(diff_bandwidth_accuracy, key=diff_bandwidth_accuracy.get)\n",
    "        \n",
    "        # append the best bandwidth to dictionary \n",
    "        # which stores best bandwidth for all partitions\n",
    "        kf_bandwidth_max.append(max_prob_bandwidth)\n",
    "    \n",
    "    # average of the best bandwidths found in each partition\n",
    "    avg = sum(kf_bandwidth_max)/len(kf_bandwidth_max)\n",
    "    \n",
    "    print(\"cross validation bandwidth completed.\")\n",
    "    \n",
    "    return avg\n",
    "\n",
    "# displays the kde vs attribute to show the effect \n",
    "# when bandwidth = 5 vs bandwidth = 10\n",
    "# here only displays for attribute x1 of class = bridge\n",
    "def display_kde(best_bandwidth, arbitrary_bandwidth):\n",
    "\n",
    "    ax = plt.gca()\n",
    "    x1=[instance[0] for instance in class_dict_q4['bridge']]\n",
    "    kde_best_bandwidth=[]\n",
    "    for i in range(len(x1)):           \n",
    "        x1_prob = 0\n",
    "        for j in range(len(x1)):\n",
    "            gaussian_kde = (gaussian_distribution(x1[i],x1[j],best_bandwidth))\n",
    "            x1_prob+=gaussian_kde\n",
    "        kde_best_bandwidth.append(x1_prob/len(x1))\n",
    "        \n",
    "    dict_best = {'x1':x1,('kde_'+str(best_bandwidth)):kde_best_bandwidth}\n",
    "    df_best= pd.DataFrame.from_dict(dict_best)\n",
    "    df_best.sort_values(by=['x1'],inplace=True)\n",
    "    df_best.plot(kind='line',x='x1',y=('kde_'+str(best_bandwidth)),color='red',ax=ax)\n",
    "\n",
    "    \n",
    "    kde_arbitrary_bandwidth=[]\n",
    "    for i in range(len(x1)):           \n",
    "        x1_prob = 0\n",
    "        for j in range(len(x1)):\n",
    "            gaussian_kde = (gaussian_distribution(x1[i],x1[j],arbitrary_bandwidth))\n",
    "            x1_prob+=gaussian_kde\n",
    "        kde_arbitrary_bandwidth.append(x1_prob/len(x1))\n",
    "        \n",
    "    dict_arb = {'x1':x1,('kde_'+str(arbitrary_bandwidth)):kde_arbitrary_bandwidth}\n",
    "    df_arb= pd.DataFrame.from_dict(dict_arb)\n",
    "    df_arb.sort_values(by=['x1'],inplace=True)\n",
    "    df_arb.plot(kind='line',x='x1',y=('kde_'+str(arbitrary_bandwidth)),color='blue',ax=ax)\n",
    "    \n",
    "    ax.set_ylabel('kde')\n",
    "    ax.set_title('kde vs x1 - class = bridge')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation bandwidth running...\n",
      "cross validation bandwidth running...\n",
      "cross validation bandwidth running...\n",
      "cross validation bandwidth running...\n",
      "cross validation bandwidth running...\n",
      "cross validation bandwidth running...\n",
      "cross validation bandwidth running...\n",
      "cross validation bandwidth completed.\n",
      "predicting for best bandwidth completed.\n",
      "best bandwidth is 5.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using the best bandwidth from above:  77.67857142857143\n",
      "Accuracy using bandwidth 10 from q3:  75.0\n"
     ]
    }
   ],
   "source": [
    "# RUN HERE FOR Q4 AFTER RUNNING THE FUNCTIONS ABOVE\n",
    "\n",
    "# put training instances based on class\n",
    "class_dict_q4 = defaultdict() \n",
    "class_count_dict_q4 = defaultdict(int)\n",
    "\n",
    "# store training instances\n",
    "train_attr_vals_q4 = []\n",
    "train_classes_q4 = []\n",
    "\n",
    "# preprocess training instances\n",
    "preprocess_q4(train_attr_vals_q4, train_classes_q4)\n",
    "\n",
    "#find the best bandwidth by cross validation\n",
    "best_bandwidth = cross_val_bandwidth(class_dict_q4,class_count_dict_q4,train_attr_vals_q4,train_classes_q4)\n",
    "\n",
    "# store test instances \n",
    "test_attr_vals_q4 = []\n",
    "test_actual_class_q4 = []\n",
    "\n",
    "# open testing file, store & clean data\n",
    "test_filename = \"COMP30027_2021_assignment1_data/test.csv\"\n",
    "open_train_file(test_attr_vals_q4,test_actual_class_q4,test_filename)\n",
    "remove_missing_values(test_attr_vals_q4)\n",
    "\n",
    "print(\"predicting for best bandwidth completed.\")\n",
    "print(\"best bandwidth is\",best_bandwidth)\n",
    "\n",
    "# find the predicted classes for the test instances when using best bandwidth found\n",
    "predicted_q4 = predict_kde(best_bandwidth,test_attr_vals_q4,class_dict)\n",
    "\n",
    "# find accuracy comparing to actual classes\n",
    "accuracy_kde_q4 = evaluate(test_actual_class_q4, predicted_q4)\n",
    "\n",
    "\n",
    "# displays the kde vs attribute to show the effect \n",
    "# when using best bandwidth found vs arbitrary bandwidth\n",
    "display_kde(best_bandwidth,10)\n",
    "\n",
    "print(\"Accuracy using the best bandwidth from above: \",accuracy_kde_q4)\n",
    "print(\"Accuracy using bandwidth 10 from q3: \",accuracy_kde_q3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5\n",
    "Naive Bayes ignores missing values, but in pose recognition tasks the missing values can be informative. Missing values indicate that some part of the body was obscured and sometimes this is relevant to the pose (e.g., holding one hand behind the back). Are missing values useful for this task? Implement a method that incorporates information about missing values and demonstrate whether it changes the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for Q5\n",
    "\n",
    "# find the mean values of each attribute per class\n",
    "def mean_of_class(class_dict, mean_dict):\n",
    "    mean_dict_val = 0\n",
    "    mean_class_attribute = []\n",
    "    for keys in class_dict.keys():\n",
    "        mean_dict[keys] = []\n",
    "        for i in range(len(class_dict[keys][0])):\n",
    "            for j in range(len(class_dict[keys])):\n",
    "                mean_class_attribute.append(class_dict[keys][j][i])\n",
    "                \n",
    "            mean_dict_val = mean(mean_class_attribute)\n",
    "            mean_dict[keys].append(mean_dict_val)\n",
    "            mean_dict_val = 0\n",
    "            mean_class_attribute = []    \n",
    "            \n",
    "    return mean_dict\n",
    "\n",
    "# impute missing values with mean\n",
    "def impute_mean(mean_dict, new_class_dict):\n",
    "    for keys in new_class_dict.keys():\n",
    "        for i in range(len(new_class_dict[keys])): #num instances\n",
    "            for j in range(len(new_class_dict[keys][0])):\n",
    "                if (new_class_dict[keys][i][j] == 0):\n",
    "                    new_class_dict[keys][i][j] = mean_dict[keys][j]\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0-imputation  Mean imputation\n",
      "Gaussian            73.21          73.21     \n",
      "KDE                 75.0           69.64     \n"
     ]
    }
   ],
   "source": [
    "# RUN HERE FOR Q5 AFTER RUNNING FUNCTIONS ABOVE\n",
    "\n",
    "mean_dict = defaultdict()\n",
    "new_class_dict = class_dict\n",
    "mean_dict = mean_of_class(class_dict, mean_dict)\n",
    "\n",
    "# impute missing values with the mean of respective attribute of the class\n",
    "impute_mean(mean_dict, new_class_dict)\n",
    "\n",
    "training_details_q5 = defaultdict()\n",
    "\n",
    "# train the new dataset\n",
    "train(new_class_dict, class_count_dict, training_details_q5, attr_num, total_instances)\n",
    "\n",
    "# store values of testing instances\n",
    "test_attr_vals_q5=[]\n",
    "\n",
    "# store actual class of testing instances\n",
    "test_actual_class_q5=[]\n",
    "predicted_classes_q5 =[]\n",
    "\n",
    "# predicted classes of the testing instances\n",
    "predicted_classes_q5 = predict(training_details_q5,attr_num,len(training_details_q5.keys()),test_attr_vals_q5,test_actual_class_q5)\n",
    "\n",
    "predicted_q5 = predict_kde(5,test_attr_vals_q5,class_dict)\n",
    "accuracy_kde_q5 = evaluate(test_actual_class_q5, predicted_q5)\n",
    "\n",
    "#evaluate accuracy\n",
    "new_accuracy = evaluate(test_actual_class_q5,predicted_classes_q5)\n",
    "\n",
    "print(\"{:<15}{:^15}{:^15}\".format(\"\", \"0-imputation\", \"Mean imputation\"))\n",
    "print(\"{:<15}{:^15}{:^15}\".format(\"Gaussian\", round(accuracy,2) , round(new_accuracy,2)))\n",
    "print(\"{:<15}{:^15}{:^15}\".format(\"KDE\", round(accuracy_kde_q3,2) , round(accuracy_kde_q5,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "Engineer your own pose features from the provided keypoints. Instead of using the (x,y) positions of keypoints, you might consider the angles of the limbs or body, or the distances between pairs of keypoints. How does a naive Bayes classifier based on your engineered features compare to the classifier using (x,y) values? Please note that we are interested in explainable features for pose recognition, so simply putting the (x,y) values in a neural network or similar to get an arbitrary embedding will not receive full credit for this question. You should be able to explain the rationale behind your proposed features. Also, don't forget the conditional independence assumption of naive Bayes when proposing new features -- a large set of highly-correlated features may not work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
